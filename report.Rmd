---
documentclass: report
link-citations: true
urlcolor: blue
bibliography: references.bib
linestretch: 1.5
fontsize: 12pt
output:
  bookdown::pdf_document2:
    toc: true
    toc_depth: 3
    includes:
      in_header: preamble.tex
    extra_dependencies: ["mathptmx", "longtable"]
title: |
  | Assignment 29
  | Statistical Analysis of the Grit Scale Dataset \vspace{1cm}
  | ![](figures/sigillum-lmu.png){width=3cm}       \vspace{1cm}
  | ![](figures/aueb.jpg){width=9cm}               \vspace{1cm}
subtitle: |
  | Submitted to the Department of Statistics
  | of the Athens University of Economics and Business
author: |
  | By
  | Maximilian Schneider
date: "`r format(Sys.time(), '%d.%m.%Y')`"
abstract: |
  Lorem ipsum dolor sit amet, consectetur adipiscing elit.
  Integer fringilla interdum magna, at sodales ante hendrerit in.
  Ut mauris justo, sodales sed posuere id, ultrices ut ante.
  In auctor tellus nulla, nec efficitur tellus finibus id.
  Vivamus at condimentum sapien, a sodales erat.
  Nulla nec neque eu purus consequat vestibulum.
  Vestibulum placerat congue porttitor.
  In hac habitasse platea dictumst.
  In hac habitasse platea dictumst.
  Sed consectetur a quam a posuere.
  Ut elit leo, lobortis sit amet risus vel, ultrices fringilla nisl.
  Aliquam ut leo mauris.
  Suspendisse neque tellus, aliquet ac dignissim vitae, gravida sit amet elit.
  Ut eget turpis ac sem aliquet scelerisque.
  Phasellus in maximus est.
---

<style>
body {
text-align: justify}
.main-container {
  max-width: 1000px;
  margin-left: auto;
  margin-right: auto;
}
</style>

# Introduction

```{r setup1, include=FALSE}
# rmarkdown settings
knitr::opts_chunk$set(fig.align = "center", out.width = '80%', include = FALSE, echo = FALSE,
                      cache = FALSE, message = FALSE, warning = FALSE)

# packages
library(data.table)
library(purrr)
library(magrittr)
library(ggplot2); theme_set(theme_bw())
```

```{r setup2, cache=FALSE}
source("R/prepare-data.R")
source("R/my-functions.R")
source("R/my-plots.R")
source("R/my-models.R")
```

As part of the Data Analysis course of the Athens University of Economics and Business a dataset is to be analyzed.
This report describes the applied methods and corresponding findings.
The assigned dataset "grit scale data" originates from the study "Development and Validation of the Short Grit Scale (Grit-S)" [@duckworth2009development].

# Modeling of the openness score

## Grit Scale Dataset

### Overview

```{r data-structure}
str(dt_bigf)
summary(dt_bigf)
```

The given grit scale dataset consists of various measurements on 4270 individuals.
After preparing the dataset according to the assignment, there are 22 distinct variables.
They can be divided into 8 automatically collected technical information about the device used to complete the questionnaire, 12 personal details about the subject and two generated scores, eloquence and openness, which are described in Sections \@ref(eloquence-score) and \@ref(openness-score), respectively.

The goal is to find a suitable regression model for the openness score using the rest of the variables and by applying the methods learned in class.
While all 12 personal details (education, urban, gender, native language English, age, hand, religion, orientation, race, voted, married, family size) will be considered, the technical information is only used to exclude unrealistic observations.

### Eloquence score

During the course of the questionnaire, participants where given a list of 16 words, three of which were not real, and tasked to mark all the words whose definitions they were sure to know.
In order to consider this in the analysis, the variables are aggregated to a single score via the sum of correct answers.
Because the questionnaire only had one box for each item, ticked meaning "I know the definition", it is assumed there are no missing observations for this set of items, which non the less could be the case, because an unchecked box could mean both.

Figure \@ref(fig:plot-eloquence) displays a barchart of the score.

```{r plot-eloquence, include=TRUE, fig.cap='(ref:plot-eloquence)'}
p <- ggplot(dt_bigf, aes(x = eloquence)) +
  geom_bar(color = "#606161", fill = "#606161") +
  scale_x_continuous(breaks = seq(0, 16, 4)) +
  labs(x = "Eloquence score", y = "Number of observations")
p
```
(ref:plot-eloquence) First figure.

```{r}
p <- ggplot(dt_bigf, aes(x = eloquence)) +
  geom_histogram(aes(y = ..density..), breaks = seq(0, 1, length = 200),
                 color = "black", fill = "white") +
  geom_density() +
  geom_function(fun = dnorm, args = dnorm_args(dt_bigf$eloquence), color = "red")

p <- ggplot(dt_bigf, aes(x = eloquence)) +
  stat_ecdf() +
  geom_function(fun = pnorm, args = dnorm_args(dt_bigf$eloquence), color = "red")
```

### Openness score

<!-- TODO: Mention somewhere this is going to be the response -->

In order to asses the openness of an individual (in terms of the Big Five personality dimensions) ten questions were asked, which are to be aggregated into a single score.
Its calculation is a bit more involved compared to the eloquence score.

1) The openness items are measured on a Likert-type scale ranging from 0 (Disagree strongly) to 4 (Agree strongly).
1) There is the option to not answer the question.
1) Questions 2, 4 and 6 are formulated in a way that a higher number indicates a lower openness.
   This shows up in Figure \@ref(fig:plot-openness-items), which depicts the correlation of the individual openness items.
   For these measures $4 - x_\text{O}$ is considered.

```{r plot-openness-items, include=TRUE, fig.cap='(ref:plot-openness-items)'}
cowplot::plot_grid(p_corr1, p_corr2)
```
(ref:plot-openness-items) Pairwise Pearson correlations of items testing the Big Five personality dimension "openness" before and after transforming items 2, 4 and 6.

Taking into account these points, the item scores are summed up and divided by four times the number of items answered.
This results in a pseudo continuous score ranging from zero to one, with 60 unique values.
The associated histogram is shown in Figure \@ref(fig:plot-openness).
Possible scores are multiples of $\frac{1}{40}$ (all ten openness items completed), $\frac{1}{36}$ (nine openness items completed), $\frac{1}{32}$ and so on.

```{r plot-openness, include=TRUE, fig.cap='(ref:plot-openness)'}
p <- ggplot(dt_bigf, aes(x = openness)) +
  geom_histogram(aes(y = ..density..), breaks = seq(0, 1, length = 200), color = "#606161",
                 fill = "#606161") +
  geom_function(fun = dnorm, args = dnorm_args(dt_bigf$openness), color = "#0075be", size = 1) +
  geom_density(size = 1) +
  labs(x = "Openness score", y = "Density")
p
```
(ref:plot-openness) Second figure.

```{r}
p <- ggplot(dt_bigf, aes(x = openness)) +
  stat_ecdf() +
  geom_function(fun = pnorm, args = dnorm_args(dt_bigf$openness), color = "red")

p <- ggplot(dt_bigf, aes(sample = openness)) +
  geom_qq() +
  geom_qq_line()
```

## Pairwise associations with openness

### Continuous

* Eloquence makes sense.
* There should be no correlation with age.
* Figure \@ref(fig:openness-continuous)

```{r openness-continuous, include=TRUE, fig.cap='(ref:openness-eloquence)'}
p1 <- ggplot(dt_bigf, aes(x = eloquence, y = openness)) +
  geom_jitter(height = 0, width = 0.3, alpha = 0.3) +
  geom_smooth(color = "#0075be", size = 1) +
  labs(x = "Eloquence score", y = "Openness score")

p2 <- ggplot(dt_bigf, aes(x = age, y = openness)) +
  geom_jitter(height = 0, width = 0.3, alpha = 0.3) +
  geom_smooth(color = "#0075be", size = 1) +
  labs(x = "Age", y = "Openness score")

p3 <- ggplot(dt_bigf[familysize < 20,], aes(x = familysize, y = openness)) +
  geom_jitter(height = 0, width = 0.3, alpha = 0.3) +
  geom_smooth(color = "#0075be", size = 1) +
  labs(x = "Family size", y = "Openness score")

cowplot::plot_grid(p1, p2, p3, nrow = 2)
```
(ref:openness-eloquence) Fourth figure.

### Discrete

```{r openness-discrete, include = TRUE}
f_measurements <- function(dt, var) {
  n_na <- sum(is.na(dt[, .SD, .SDcols = var]))
  dt[, .(mean = mean(openness, na.rm = TRUE), sd = sd(openness, na.rm = TRUE),
         median = median(openness, na.rm = TRUE),
         NAs_O = scales::percent(sum(is.na(openness)) / .N, accuracy = 0.01)), by = var] %>%
    setnames(old = var, new = "level") %>%
    .[is.na(level), level := paste0("NA (", n_na, ")")] %>%
    .[, covariate := var] %>%
    .[]
}

c("education", "urban", "gender", "engnat", "hand", "religion", "orientation", "race", "voted",
  "married") %>%
  lapply(f_measurements, dt = dt_bigf) %>%
  do.call(what = rbind) %>%
  setcolorder(c("covariate", "level", "median", "mean", "sd", "NAs_O")) %>%
  setnames(c("Covariate", "Level", "Median", "Mean", "SD", "Share NAs")) %>%
  knitr::kable(digits = 2, booktabs = TRUE, longtable = TRUE) %>%
  kableExtra::collapse_rows(columns = 1, latex_hline = "major", valign = "top") %>%
  kableExtra::kable_styling(latex_options = "repeat_header")
```

<!--
### Technical data

```{r duration}
ggplot(dt_bigf[introelapse < 500,], aes(x = introelapse, y = openness)) +
  geom_jitter(height = 0.01, width = 0.00, alpha = 0.5) +
  geom_smooth()

ggplot(dt_bigf[testelapse < 1000,], aes(x = testelapse, y = openness)) +
  geom_jitter(height = 0.01, width = 0.00, alpha = 0.5) +
  geom_smooth()

ggplot(dt_bigf[surveyelapse < 1000,], aes(x = surveyelapse, y = openness)) +
  geom_jitter(height = 0.01, width = 0.00, alpha = 0.5) +
  geom_smooth()
```

```{r browser-os}
ggplot(dt_bigf, aes(x = browser, y = openness)) +
  geom_boxplot()

ggplot(dt_bigf, aes(x = os, y = openness)) +
  geom_boxplot()
```

### Eloquence and engnat

```{r eloquence-engnat, include=TRUE}
ggplot(dt_bigf, aes(x = engnat, y = eloquence)) +
  geom_boxplot() +
  geom_hline(yintercept = dt_bigf[, median(eloquence, na.rm = TRUE)])
```

### Eloquence and education

```{r eloquence-education, include=TRUE}
ggplot(dt_bigf[!is.na(education),], aes(x = education, y = eloquence)) +
  geom_boxplot() +
  geom_hline(yintercept = dt_bigf[, median(eloquence, na.rm = TRUE)])
```

### Age and education

```{r age-education, include=TRUE}
ggplot(dt_bigf[!is.na(education),], aes(x = education, y = age)) +
  geom_boxplot() +
  geom_hline(yintercept = dt_bigf[, median(age, na.rm = TRUE)])
```
-->

```{r}
# TODO: remove
knitr::opts_chunk$set(eval = FALSE)
```

## Linear model with smooth effect

* TODO: try centering data
* TODO: don't forget outlier
* TODO: choose a nice reference category
* No need for checking correlation between covariates: exhaustive model selection (variables that don't add new information are dropped)

* Variable selection: Use BIC or else nothing gets filtered
* Search complete model space, because I can

# Conclusion

Blub.

# References

<div id="refs"></div>

# (APPENDIX) Appendix {-}

# Model selection

* Binomial model
* Quasibinomial
* Estimation

<!-- trash -->
```{r first-attempt, eval=FALSE}
dt_bigf[, openness := rowSums(.SD) / 50, .SDcols = patterns("^O")]
0:50 / 50  # possible scores
# dt_bigf[, patterns("^[ACENOG]") := NULL]

ggplot(dt_bigf, aes(x = openness)) +
  geom_histogram(aes(y = ..density..), bins = 100, boundary = 0) +
  geom_function(fun = dnorm, args = list(mean = mean(dt_bigf$openness), sd = sd(dt_bigf$openness))) +
  geom_density(color = "red")

ggplot(dt_bigf, aes(x = openness)) +
  stat_ecdf()
```

